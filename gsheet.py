import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from utils import normalize_columns, remove_duplicate_and_empty_cols, parse_dates
from config import REQUIRED_SHEETS, DATE_COLS

# =========================================================
# ‚úÖ 1. K·∫æT N·ªêI (CACHE RESOURCE)
# =========================================================
@st.cache_resource(show_spinner=False)
def connect_gsheet():
    creds_info = st.secrets["gdrive"]
    creds = Credentials.from_service_account_info(
        creds_info,
        scopes=["https://www.googleapis.com/auth/spreadsheets"]
    )
    client = gspread.authorize(creds)
    return client

# =========================================================
# ‚úÖ 2. T·∫¢I 1 SHEET (CACHE DATA) - ƒê√É S·ª¨A L·ªñI ARROW
# =========================================================
@st.cache_data(show_spinner=False)
def load_sheet_df(sheet_name: str) -> pd.DataFrame:
    try:
        gc = connect_gsheet()
        sh = gc.open_by_key(st.secrets["gdrive"]["spreadsheet_id"])
        ws = sh.worksheet(sheet_name)
        data = ws.get_all_records()
        
        df = pd.DataFrame(data)

        if df.empty:
            return df

        # Chu·∫©n h√≥a t√™n c·ªôt
        df = normalize_columns(df)
        df = remove_duplicate_and_empty_cols(df)

        # ---------------------------------------------------------
        # üõ†Ô∏è FIX L·ªñI CRASH: √âp ki·ªÉu String cho c√°c c·ªôt d·ªÖ g√¢y l·ªói
        # ---------------------------------------------------------
        force_str_cols = [
            "DIEN_THOAI", "SDT", "MOBILE", 
            "SO_TAI_KHOAN", "STK", 
            "MA_SO_THUE", "MST", 
            "CCCD", "CMND",
            "ID_NHAN_SU", "ID_DON_VI" # C√°c c·ªôt ID c≈©ng n√™n l√† string
        ]
        
        for col in force_str_cols:
            if col in df.columns:
                # Chuy·ªÉn sang string v√† x·ª≠ l√Ω NaN
                df[col] = df[col].astype(str).replace("nan", "")

        # Parse ng√†y
        df = parse_dates(df, DATE_COLS)

        return df

    except Exception as e:
        # Log l·ªói nh∆∞ng tr·∫£ v·ªÅ DataFrame r·ªóng ƒë·ªÉ app kh√¥ng s·∫≠p ho√†n to√†n
        print(f"‚ùå L·ªói t·∫£i sheet '{sheet_name}': {e}")
        return pd.DataFrame()

# =========================================================
# ‚úÖ 3. T·∫¢I T·∫§T C·∫¢ SHEET
# =========================================================
@st.cache_data(show_spinner=False)
def load_all_sheets() -> dict:
    all_data = {}
    for sheet in REQUIRED_SHEETS:
        df = load_sheet_df(sheet)
        all_data[sheet] = df
    return all_data

# =========================================================
# ‚úÖ 4. GHI D·ªÆ LI·ªÜU
# =========================================================
def save_raw_sheet(sheet_name: str, df: pd.DataFrame):
    try:
        gc = connect_gsheet()
        sh = gc.open_by_key(st.secrets["gdrive"]["spreadsheet_id"])

        try:
            ws = sh.worksheet(sheet_name)
        except:
            ws = sh.add_worksheet(title=sheet_name, rows=2000, cols=50)

        ws.clear()

        # Chu·∫©n b·ªã d·ªØ li·ªáu ghi
        df = df.fillna("")
        
        # Chuy·ªÉn t·∫•t c·∫£ v·ªÅ string tr∆∞·ªõc khi ghi ƒë·ªÉ tr√°nh l·ªói JSON
        df_to_save = df.astype(str)
        
        values = [df.columns.tolist()] + df_to_save.values.tolist()

        ws.update(values)

        # X√≥a cache
        load_sheet_df.clear()
        load_all_sheets.clear()

        st.success(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o sheet '{sheet_name}'")
        st.rerun()

    except Exception as e:
        st.error(f"‚ùå L·ªói l∆∞u sheet '{sheet_name}': {e}")
